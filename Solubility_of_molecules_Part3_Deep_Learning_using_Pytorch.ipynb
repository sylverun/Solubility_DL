{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28764a61",
   "metadata": {},
   "source": [
    "# Chemoinformatics using Python: Predict Solubility with ML and DL models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2a366",
   "metadata": {},
   "source": [
    "## Part III:  DL using Pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70913f",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8624e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdkit package for data formatting\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors,rdMolDescriptors, Draw, PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem.rdMolDescriptors import CalcExactMolWt\n",
    "from rdkit.Chem.Descriptors import MolLogP\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "\n",
    "#general package for data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#torch package for Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import session_info\n",
    "session_info.show()\n",
    "\n",
    "# graphical card for pytorch\n",
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5e2e1",
   "metadata": {},
   "source": [
    "### List of definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5dd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniq_smiles (smiles):\n",
    "    mols =[Chem.MolFromSmiles(smil) for smil in smiles]\n",
    "    smiles = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "    return smiles\n",
    "\n",
    "def gen_avfpts_2(df):\n",
    "    Av_fpts = [pyAvalonTools.GetAvalonFP(struct, nBits = 1600) for struct in tqdm (df.Structure)]\n",
    "    return np.array(Av_fpts)\n",
    "\n",
    "def generate_descriptors(df,verbose = False):\n",
    "    mol_liste= [Chem.MolFromSmiles(element) for element in df.smiles]\n",
    "    base_data= np.arange(1,1)\n",
    "    i=0\n",
    "    for mol in mol_liste:\n",
    "        descr_Mw= CalcExactMolWt(mol)\n",
    "        descr_logP= MolLogP(mol)\n",
    "        \n",
    "        row= np.array([descr_Mw,descr_logP,\n",
    "                      ])\n",
    "        if (i==0):\n",
    "            base_data= row\n",
    "        else:\n",
    "            base_data = np.vstack([base_data,row])\n",
    "        i=i+1\n",
    "        \n",
    "    colnames= [\"MolWt\", \"logP\"]\n",
    "    descriptor= pd.DataFrame(data= base_data, columns= colnames)\n",
    "    \n",
    "    return descriptor\n",
    "\n",
    "def generate_dataframe(path):\n",
    "    df=pd.read_csv(path)\n",
    "    Uniq_Smiles = uniq_smiles(df.smiles)\n",
    "    df['smiles'] = Uniq_Smiles\n",
    "    duplicate_smile= df[df['smiles'].duplicated()]['smiles'].values\n",
    "    df[df['smiles'].isin(duplicate_smile)].sort_values(by= ['smiles'])\n",
    "    df_clean= df.drop_duplicates(subset=['smiles']).reset_index(drop= True)\n",
    "    PandasTools.AddMoleculeColumnToFrame(df_clean, 'smiles', 'Structure')\n",
    "    av_fpts=gen_avfpts_2(df_clean)\n",
    "    dataframe_fpts= pd.DataFrame(av_fpts)\n",
    "    df_descrip= generate_descriptors(df_clean)\n",
    "    dataset= dataframe_fpts.join(df_descrip, how='left').join(df_clean['logS'], how='left')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f717583",
   "metadata": {},
   "source": [
    "#### Import of the dataset and generate features for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2078787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8701/8701 [00:03<00:00, 2808.47it/s]\n",
      "100%|██████████| 2001/2001 [00:00<00:00, 3535.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8  9  ...  1593  1594  1595  1596  1597  1598  \\\n",
      "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
      "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
      "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
      "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
      "4  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
      "\n",
      "   1599       MolWt    logP    logS  \n",
      "0     0   56.037222 -1.3084 -4.7424  \n",
      "1     0  183.852324  2.2474 -1.7415  \n",
      "2     0  183.852324  2.2474 -1.3195  \n",
      "3     0  327.673348  3.1773 -3.1404  \n",
      "4     0  249.762836  2.4547 -1.9113  \n",
      "\n",
      "[5 rows x 1603 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1593</th>\n",
       "      <th>1594</th>\n",
       "      <th>1595</th>\n",
       "      <th>1596</th>\n",
       "      <th>1597</th>\n",
       "      <th>1598</th>\n",
       "      <th>1599</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>logP</th>\n",
       "      <th>logS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327.673348</td>\n",
       "      <td>3.1773</td>\n",
       "      <td>-3.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249.762836</td>\n",
       "      <td>2.4547</td>\n",
       "      <td>-1.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>341.688998</td>\n",
       "      <td>3.2182</td>\n",
       "      <td>-2.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162.004412</td>\n",
       "      <td>2.7140</td>\n",
       "      <td>-2.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.852324</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-1.165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  1593  1594  1595  1596  1597  1598  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   1599       MolWt    logP   logS  \n",
       "0     0  327.673348  3.1773 -3.140  \n",
       "1     0  249.762836  2.4547 -1.808  \n",
       "2     0  341.688998  3.2182 -2.732  \n",
       "3     0  162.004412  2.7140 -2.294  \n",
       "4     0  171.852324  1.7337 -1.165  \n",
       "\n",
       "[5 rows x 1603 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r\"C:\\Users\\sylv_\\Desktop\\GitHub\\SolCuration\\clean\\aqsol_stand.csv\"\n",
    "path_test=r\"C:\\Users\\sylv_\\Desktop\\GitHub\\SolCuration\\clean\\phys_stand.csv\"\n",
    "\n",
    "dataset_aqsol=generate_dataframe(path)\n",
    "dataset_phys=generate_dataframe(path_test)\n",
    "\n",
    "print(dataset_aqsol.head())\n",
    "dataset_phys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9770c03",
   "metadata": {},
   "source": [
    "#### Normalization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8189e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MolWt      logP\n",
      "0 -1.474927 -1.592555\n",
      "1 -0.432384 -0.058573\n",
      "2 -0.432384 -0.058573\n",
      "3  0.740714  0.342588\n",
      "4  0.105225  0.030857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MolWt</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.740714</td>\n",
       "      <td>0.342588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105225</td>\n",
       "      <td>0.030857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.855035</td>\n",
       "      <td>0.360233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.610590</td>\n",
       "      <td>0.142719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.530264</td>\n",
       "      <td>-0.280185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-1.246817</td>\n",
       "      <td>-0.273972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.463245</td>\n",
       "      <td>0.172486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.854970</td>\n",
       "      <td>-0.847005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.609682</td>\n",
       "      <td>-0.210082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>-1.279166</td>\n",
       "      <td>-0.822501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MolWt      logP\n",
       "0     0.740714  0.342588\n",
       "1     0.105225  0.030857\n",
       "2     0.855035  0.360233\n",
       "3    -0.610590  0.142719\n",
       "4    -0.530264 -0.280185\n",
       "...        ...       ...\n",
       "1996 -1.246817 -0.273972\n",
       "1997 -0.463245  0.172486\n",
       "1998 -0.854970 -0.847005\n",
       "1999 -0.609682 -0.210082\n",
       "2000 -1.279166 -0.822501\n",
       "\n",
       "[2001 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two DataFrames vertically with their columns to normalize\n",
    "combined_df = pd.concat([dataset_aqsol.iloc[:, -3:-1], dataset_phys.iloc[:, -3:-1]], axis=0)\n",
    "\n",
    "# Apply the scaler to the data\n",
    "scaler = StandardScaler()\n",
    "normalized_data=scaler.fit_transform(combined_df)\n",
    "\n",
    "# Split the normalized data back into two separate DataFrames\n",
    "dataset_aqsol_normalized = pd.DataFrame(normalized_data[:len(dataset_aqsol.iloc[:, -3:-1])], columns=dataset_aqsol.iloc[:, -3:-1].columns)\n",
    "dataset_phys_normalized = pd.DataFrame(normalized_data[len(dataset_aqsol.iloc[:, -3:-1]):], columns=dataset_phys.iloc[:, -3:-1].columns)\n",
    "\n",
    "print(dataset_aqsol_normalized.head())\n",
    "dataset_phys_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c247e3",
   "metadata": {},
   "source": [
    "#### Replace the columns in the corresponding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd72d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aqsol.iloc[:, -3:-1] = dataset_aqsol_normalized\n",
    "dataset_phys.iloc[:, -3:-1] = dataset_phys_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca182522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1593</th>\n",
       "      <th>1594</th>\n",
       "      <th>1595</th>\n",
       "      <th>1596</th>\n",
       "      <th>1597</th>\n",
       "      <th>1598</th>\n",
       "      <th>1599</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>logP</th>\n",
       "      <th>logS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.474927</td>\n",
       "      <td>-1.592555</td>\n",
       "      <td>-4.7424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.432384</td>\n",
       "      <td>-0.058573</td>\n",
       "      <td>-1.7415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.432384</td>\n",
       "      <td>-0.058573</td>\n",
       "      <td>-1.3195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740714</td>\n",
       "      <td>0.342588</td>\n",
       "      <td>-3.1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105225</td>\n",
       "      <td>0.030857</td>\n",
       "      <td>-1.9113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  1593  1594  1595  1596  1597  1598  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   1599     MolWt      logP    logS  \n",
       "0     0 -1.474927 -1.592555 -4.7424  \n",
       "1     0 -0.432384 -0.058573 -1.7415  \n",
       "2     0 -0.432384 -0.058573 -1.3195  \n",
       "3     0  0.740714  0.342588 -3.1404  \n",
       "4     0  0.105225  0.030857 -1.9113  \n",
       "\n",
       "[5 rows x 1603 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_aqsol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2eda22",
   "metadata": {},
   "source": [
    "#### Converting  data of the training dataset into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eade4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_aqsol.iloc[:, :-1].values\n",
    "y = dataset_aqsol.iloc[:, -1].values\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y)\n",
    "y = y.view((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1867fd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -1.4749, -1.5926],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.4324, -0.0586],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.4324, -0.0586],\n",
      "        ...,\n",
      "        [ 0.0000,  1.0000,  0.0000,  ...,  0.0000, -1.3689, -1.1124],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.9528, -0.8759],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.9447, -1.1369]])\n"
     ]
    }
   ],
   "source": [
    "# take the size of the features and  \n",
    "inputs_shape= X.shape[1]\n",
    "print(inputs_shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad3393",
   "metadata": {},
   "source": [
    "#### Define the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5e20ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=inputs_shape, out_features=1024)\n",
    "        self.fc1p = nn.LeakyReLU(0.1)\n",
    "        self.fc0 = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.fc2p = nn.LeakyReLU(0.1)\n",
    "        self.fc3 = nn.Dropout(p=0.14)\n",
    "        self.fc4 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.fc4p = nn.LeakyReLU(0.1)\n",
    "        self.fc5 = nn.Dropout(p=0.18)\n",
    "        self.fc6 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc6p = nn.LeakyReLU(0.1)\n",
    "        self.fc7 = nn.Dropout(p=0.2)\n",
    "        self.fc8 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc8p = nn.LeakyReLU(0.1)\n",
    "        self.fc10 = nn.Linear(in_features=64, out_features=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1p(x)\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2p(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.fc4p(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.fc6p(x)\n",
    "        x = self.fc7(x)\n",
    "        x = self.fc8(x)\n",
    "        x = self.fc8p(x)\n",
    "        x = self.fc10(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7cc9ce",
   "metadata": {},
   "source": [
    "#### Construction of the training and validation dataset and their corresponding loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed8acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "\n",
    "\n",
    "dataset = MyDataset(X, y)\n",
    "train_dataset, val_dataset = random_split(dataset, [round(len(dataset)*0.8),round(len(dataset)*0.2)])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6bb7c",
   "metadata": {},
   "source": [
    "#### Instantiation of the network and definition of the loss, optimizer and some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f5a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device) # important to direct the network on the gpu\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, verbose=True)\n",
    "num_epoch=15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4e2b2",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f416f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/15, loss = 0.847\n",
      "Epoch 1 Validation loss: 1.717, r2_val = 0.680\n",
      "epoch 2/15, loss = 1.226\n",
      "Epoch 2 Validation loss: 1.218, r2_val = 0.774\n",
      "epoch 3/15, loss = 0.583\n",
      "Epoch 3 Validation loss: 1.133, r2_val = 0.789\n",
      "epoch 4/15, loss = 0.515\n",
      "Epoch 4 Validation loss: 1.131, r2_val = 0.789\n",
      "epoch 5/15, loss = 0.748\n",
      "Epoch 5 Validation loss: 1.191, r2_val = 0.778\n",
      "epoch 6/15, loss = 1.345\n",
      "Epoch 6 Validation loss: 1.414, r2_val = 0.738\n",
      "epoch 7/15, loss = 0.753\n",
      "Epoch 7 Validation loss: 0.942, r2_val = 0.825\n",
      "epoch 8/15, loss = 1.806\n",
      "Epoch 8 Validation loss: 1.828, r2_val = 0.661\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-03.\n",
      "epoch 9/15, loss = 1.217\n",
      "Epoch 9 Validation loss: 0.921, r2_val = 0.830\n",
      "epoch 10/15, loss = 0.828\n",
      "Epoch 10 Validation loss: 0.814, r2_val = 0.849\n",
      "epoch 11/15, loss = 0.678\n",
      "Epoch 11 Validation loss: 0.810, r2_val = 0.849\n",
      "epoch 12/15, loss = 0.628\n",
      "Epoch 12 Validation loss: 0.796, r2_val = 0.852\n",
      "epoch 13/15, loss = 0.662\n",
      "Epoch 13 Validation loss: 0.799, r2_val = 0.852\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-04.\n",
      "epoch 14/15, loss = 0.745\n",
      "Epoch 14 Validation loss: 0.792, r2_val = 0.853\n",
      "epoch 15/15, loss = 0.480\n",
      "Epoch 15 Validation loss: 0.796, r2_val = 0.852\n"
     ]
    }
   ],
   "source": [
    "#Training loop:\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        inputs = inputs.to(device)\n",
    "        labels= labels.to(device) # important to direct the values on the gpu for calculation\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Validation to see if the model is overfitting\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        y_pred_list=[]\n",
    "        y_true_list=[]\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            y_pred = outputs.detach().cpu().numpy().flatten()\n",
    "            y_pred_list.extend(y_pred.tolist())\n",
    "            y_true_list.extend(labels.tolist())\n",
    "            r2_val = r2_score(y_true_list, y_pred_list)\n",
    "            \n",
    "    # update the scheduler for the learning rate\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    #print some information on the training process\n",
    "    print (f'epoch {epoch+1}/{num_epoch}, loss = {loss:.3f}')\n",
    "    print('Epoch %d Validation loss: %.3f' % (epoch + 1, val_loss / len(val_loader))+f', r2_val = {r2_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d63ee",
   "metadata": {},
   "source": [
    "#### Verification of the network on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9963e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.7632])\n",
      "tensor([-6.9904])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_ex= net(X[6])\n",
    "    print(y_pred_ex)\n",
    "    print(y[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ac05d",
   "metadata": {},
   "source": [
    "#### Evaluating the model on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ccd5d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=1602, out_features=1024, bias=True)\n",
       "  (fc1p): LeakyReLU(negative_slope=0.1)\n",
       "  (fc0): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2p): LeakyReLU(negative_slope=0.1)\n",
       "  (fc3): Dropout(p=0.14, inplace=False)\n",
       "  (fc4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc4p): LeakyReLU(negative_slope=0.1)\n",
       "  (fc5): Dropout(p=0.18, inplace=False)\n",
       "  (fc6): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc6p): LeakyReLU(negative_slope=0.1)\n",
       "  (fc7): Dropout(p=0.2, inplace=False)\n",
       "  (fc8): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc8p): LeakyReLU(negative_slope=0.1)\n",
       "  (fc10): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b5dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader for the training dataset\n",
    "eval_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#forward pass \n",
    "with torch.no_grad():\n",
    "    y_pred_list=[]\n",
    "    y_true_list=[]\n",
    "    for i, (inputs, labels) in enumerate(eval_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = inputs.to(device)\n",
    "            y_pred = net(inputs)\n",
    "            y_pred = y_pred.detach().cpu().numpy().flatten()  # Convert predictions to a 1D numpy array\n",
    "\n",
    "            y_pred_list.extend(y_pred.tolist())\n",
    "            y_true_list.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cba693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set have a r2 of 0.92404\n"
     ]
    }
   ],
   "source": [
    "# Obtain the r2 score on the training data\n",
    "r2 = r2_score(y_true_list, y_pred_list)\n",
    "print(f'Training set have a r2 of {r2:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f762df8",
   "metadata": {},
   "source": [
    "#### Evaluating the model  on the test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a82f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set have a r2 of 0.94603\n"
     ]
    }
   ],
   "source": [
    "# Transform the test dataset into tensors\n",
    "X_test = dataset_phys.iloc[:, :-1].values\n",
    "y_test = dataset_phys.iloc[:, -1].values\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "y_test = y_test.view((-1, 1))\n",
    "\n",
    "# torch dataset and loader for the test\n",
    "dataset_test = MyDataset(X_test, y_test)\n",
    "\n",
    "Test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "#forward pass to obtain the predict values\n",
    "with torch.no_grad():\n",
    "    y_pred_list=[]\n",
    "    y_true_list=[]\n",
    "    for i, (inputs, labels) in enumerate(Test_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = inputs.to(device)\n",
    "            y_pred = net(inputs)\n",
    "            y_pred = y_pred.detach().cpu().numpy().flatten()  # Convert predictions to a 1D numpy array\n",
    "\n",
    "            y_pred_list.extend(y_pred.tolist())\n",
    "            y_true_list.extend(labels.tolist())\n",
    "            \n",
    "#Obtain the r2for the test dataset\n",
    "r2 = r2_score(y_true_list, y_pred_list)\n",
    "print(f'Test set have a r2 of {r2:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f7469",
   "metadata": {},
   "source": [
    "#### Some remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47190f75",
   "metadata": {},
   "source": [
    "##### Note1: the two dataset have 66% percentage of repetitive molecules.\n",
    "##### Note2: The perfomence on chembl and kinect dataset are bad certainly because these dataset contains more molecules.\n",
    "##### We can train on the chembl dataset with removal of a certain number of outliers to see if their are some difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
